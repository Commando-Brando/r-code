---
title: "Assignment 1"
author: "Brandon MUller"
date: "`r Sys.Date()`"
output: openintro::lab_report
---

```{r load-packages, message=FALSE}
library(tidyverse)
library(openintro)
```

### Question 2


**Explain whether each scenario is a classification or regression prob-
lem, and indicate whether we are most interested in inference or pre-
diction. Finally, provide n and p.**

**(a) We collect a set of data on the top 500 firms in the US. For each
firm we record profit, number of employees, industry and the
CEO salary. We are interested in understanding which factors
affect CEO salary.**

- This problem is a regression scenario and we are most interested on inference because CEO salary is a quantitative variable and we are looking to understand the relationship between CEO salary and the other variables. Our n is 500 because our data set consists of 500 firms and our p is 3 for the profit, number of employees, and industry variables. 

**(b) We are considering launching a new product and wish to know
whether it will be a success or a failure. We collect data on 20
similar products that were previously launched. For each prod-
uct we have recorded whether it was a success or failure, price
charged for the product, marketing budget, competition price,
and ten other variables.**

- For each product we are trying to *classify* whether they will succeed or fail so this is a classification problem and we are interested mostly in prediction since we are trying to *predict* those outcomes. The n is 20 for the similar products to be examined. The p is 13 because the price charged for the product, marketing budget, competition price, and ten other variables were recorded for the products.

**(c) We are interested in predicting the % change in the USD/Euro
exchange rate in relation to the weekly changes in the world
stock markets. Hence we collect weekly data for all of 2012. For
each week we record the % change in the USD/Euro, the %
change in the US market, the % change in the British market,
and the % change in the German market**

- This is a regression scenario where we are interested in prediction since we are trying to predict change in USD/Euro exchange. The n is 52 since we recorded data on each week in the year 2012. Our p is 3 since we recorded the change in the US market, the change in the British market, and the change in the German market.


### Question 5

**What are the advantages and disadvantages of a very flexible (versus
a less flexible) approach for regression or classification? Under what
circumstances might a more flexible approach be preferred to a less
flexible approach? When might a less flexible approach be preferred?**

Both approaches have their pros and cons but ideally you want an approach that can fit the data best. If an approach is too flexible it can cause *over fitting* by trying too hard to find patterns in the training data, they end up including patterns that might just be random chance rather than true properties of the function. It is a good for non-linear models and it decreases bias. If an approach is not flexible at all then it becomes highly linear and can under fit the data. Although the more linear a pattern then the less flexible approach you would want.

### Question 6

**Describe the differences between a parametric and a non-parametric
statistical learning approach. What are the advantages of a para-
metric approach to regression or classification (as opposed to a non-
parametric approach)? What are its disadvantages?**

Parametric methods are 2 step approaches to training data which help reduce the problem of estimating f to its parameters. Non-parametric methods do not make explicit assumptions about the functional form of f. Parametric methods require less observations and are simpler so they are good for inference while non-parametric are generally better for more flexible functions.

### Question 8

**(a)** Use the read.csv() function to read the data into R. Call the
loaded data college. Make sure that you have the directory set
to the correct location for the data.
```{r 8a}

college <- read.csv('College.csv')

```

**(b)** Look at the data using the View() function. You should notice
that the first column is just the name of each university. We donâ€™t
really want R to treat this as data. However, it may be handy to
have these names for later. Try the following commands:
```{r 8b}

rownames(college) <- college[, 1]
View(college)
college <- college[, -1]
View(college)

```


**(c1)** Use the summary() function to produce a numerical summary
of the variables in the data set
```{r 8c1}

summary(college)

```

**(c2)**Use the pairs() function to produce a scatterplot matrix of the first ten columns or variables of the data. Recall that you can reference the first ten columns of a matrix A using A[,1:10].
```{r 8c2}

college[, 1] = as.factor(college[, 1]) 
pairs(college[, 1:10])

```

**(c3)** Use the plot() function to produce side-by-side boxplots of Outstate versus Private.
```{r 8c3}

plot(college$Private, college$Outstate, xlab = "Private Status", ylab = "Out of State Tuition", main = "Outstate Tuition for Private/Public Universities")

```
**(c4)** Create a new qualitative variable, called Elite, by binning the Top10perc variable. We are going to divide universities into two groups based on whether or not the proportion of students coming from the top 10 % of their high school classes exceeds 50 %
```{r 8c4}

Elite <- rep("No" , nrow (college))
Elite[college$Top10perc > 50] <- "Yes"
Elite <- as.factor(Elite)
college <- data.frame(college, Elite) 

summary(Elite)
plot(college$Elite, college$Outstate, xlab="Elite School", ylab="Out of State Tuition", main="Out of State Tuition for Elite/Non-Elite Schools")

```
**(c5)** Use the hist() function to produce some histograms with differing numbers of bins for a few of the quantitative vari-ables. You may find the command par(mfrow = c(2, 2)) useful: it will divide the print window into four regions so that four plots can be made simultaneously. Modifying the arguments to this function will divide the screen in other ways.
```{r 8c5}

par(mfrow = c(2, 2))
hist(college$Apps, xlab="Applications")
hist(college$Accept, xlab="Applications Accepted")
hist(college$Personal, xlab="Personal Spending")
hist(college$Books, xlab="Books Spending")

```

**(c6)** Continue exploring the data, and provide a brief summary of what you discover
```{r 8c6}

summary(college$S.F.Ratio)
summary(college$Elite)
plot(college$Elite, college$S.F.Ratio, xlab="Elite School", ylab="Student/Faculty Ratio", main="Student/Faculty Ratio for Elite/Non-Elite Schools")

```
Upon exploring the student/faculty ratio for Elite vs Non-Elite schools I have found that Elites schools generally have a smaller ratio with no outliers. Non-Elite schools have a higher median as seen in the box plot graph above and also have a minority of outliers of large ratios with one reaching a ratio of 39.80. This is what I would expect from the data since Elite schools generally a multitude of factors that allow them to have smaller class sizes which I think greatly contribute to the results displayed above.


### Question 9

**(9a)** Which of the predictors are quantitative, and which are qualitative?
```{r 9}

Auto = read.csv("Auto.csv", header=T, na.strings="?")
Auto = na.omit(Auto)

```
I think that MPG, displacement, horsepower, weight, acceleration, and year are quantitative while cylinders, origin, and name are qualitative 


**9b** What is the range of each quantitative predictor? You can an-swer this using the range() function.

```{r 9b}

range(Auto[, 1])
range(Auto[, 3])
range(Auto[, 4])
range(Auto[, 5])
range(Auto[, 6])
range(Auto[, 7])

```

**9c** What is the mean and standard deviation of each quantitative predictor?
```{r 9c}
quantitatives <- c(1, 3:7)
sapply(Auto[,quantitatives], mean)
sapply(Auto[,quantitatives], sd)

```

**9d** Now remove the 10th through 85th observations. What is the
range, mean, and standard deviation of each predictor in the
subset of the data that remains?
```{r 9d}

subAuto <- Auto[-(10:85),]
sapply(Auto[, quantitatives], range)
sapply(Auto[, quantitatives], mean)
sapply(Auto[, quantitatives], sd)

```

**9e** Using the full data set, investigate the predictors graphically,
using scatterplots or other tools of your choice. Create some plots
highlighting the relationships among the predictors. Comment
on your findings.
```{r 9e}

plot(Auto$cylinders, Auto$mpg)
plot(Auto$cylinders, Auto$horsepower)
plot(Auto$horsepower, Auto$mpg)

```
My first plot shows that generally the less cylinders a car has the more MPG is will get which makes sense since cylinders create combustion in cars which increases the amount of fuel required by the engine
The second plot compares horse power to cylinders and shows that generally the more cylinders a has the more horsepower that car can produce
The third plot shows a negative slope correlation with an overall trend of cars with lower horsepower having a high MPG

**(9f)** Suppose that we wish to predict gas mileage ( mpg) on the basis
of the other variables. Do your plots suggest that any of the
other variables might be useful in predicting mpg? Justify your
answer.

Yes, all my plots data put together shows a clear correlation between horsepower, cylinders, and mpg. Horsepower and cylinder have a positive linear relationship which can be contrasted to a negative linear slope for both those variables compared to MPG. Therefore, horsepower and cylinders can be used as predictors for MPG. More cylinders indicate more horsepower and viceversa. Both the increase of either of these or both indicate a decrease in MPG.


### Question 10

**(10a)** How many rows are in this data set? How many columns? What do the rows and columns represent?
```{r 10a}

library(ISLR2)
data(Boston)
?Boston

```

The Boston data set has 506 rows and 13 columns. Each row represents a Boston suburb and the columns represent data on each suburb.

**(10b)** Make some pairwise scatterplots of the predictors (columns) in this data set. Describe your findings.

```{r 10b}

pairs(Boston)

```
It looks like there may be some relationships between nox & dis, lstat & dis, crim & ptratio and tax * crim


**(10c)** Are any of the predictors associated with per capita crime rate? If so, explain the relationship.

There seems to be a relationship between the proportion of owner-occupied units built prior to 1940 and crime. There also appears to be a relationship between the pupil-teacher ratio by town and the crime rate. Around the 20 pupil/teacher ratio the crime rates per capita sky rockets and this is where most high crime rates are consolidated.

**(10d)** Do any of the census tracts of Boston appear to have particularly
high crime rates? Tax rates? Pupil-teacher ratios? Comment on
the range of each predictor.

```{r 10d}

summary(Boston$crim)
summary(Boston$tax)
summary(Boston$ptratio)

```
There are some suburbs in Boston that have high crime rates as we can see the crime rate max is 88.97620. Although the mean is 3.6. There are some high taxed suburbs too with the max bring 711.0 compared to the min of 187.0. Pupil-teacher ratios reach 22 while the min is 12.6 and the mean is 18.46.

**(10e)** How many of the census tracts in this data set bound the Charles river?

```{r 10e}

summary(Boston$chas == 1)

```
There appear to be 35 that bound the Charles river

**(10f)** What is the median pupil-teacher ratio among the towns in this data set?
```{r 10f}

median(Boston$ptratio)

```

**(10g)** Which census tract of Boston has lowest median value of owner-
occupied homes? What are the values of the other predictors
for that census tract, and how do those values compare to the
overall ranges for those predictors? Comment on your findings

```{r 10g}

Boston[which.min(Boston$medv),]
summary(Boston[1:5])
summary(Boston[6:9])
summary(Boston[10:12])

```
We can see that the suburb on row 399 has lowest median value of owner-occupied homes and compared to other predictors it has a high crimerate, minimum zn, a mid-high indus, min chas, high age, and high rad.

**(10h)** In this data set, how many of the census tracts average more
than seven rooms per dwelling? More than eight rooms per
dwelling? Comment on the census tracts that average more than
eight rooms per dwelling.

```{r 10h}

nrow(subset(Boston, rm > 7))
nrow(subset(Boston, rm > 8))
plot(Boston$rm, Boston$medv)

```

There are very few dwellings with 8 or more rooms while in comparison to 7 or more rooms. This means that there were 51 7 room dwellings which account for most of the 7 or more stat. This would make sense since the more rooms generally the more expensive a dwelling is so only a minority of people can afford 8 or dwellings in these suburbs.I plot the average number of rooms per dwelling against the median value of owner-occupied homes in 1000s and find that there is a pattern here where it seems that the more rooms the higher the median value of owner-occupied homes in 1000s. Specifically dwellings with 8 or more are on the high end.



